{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "\n",
    "#from recsys import *\n",
    "#from generic_preprocessing import *\n",
    "#from IPython.display import HTML\n",
    "#import pandas as pd\n",
    "\n",
    "## Importing required libraries\n",
    "import pandas as pd ## For DataFrame operation\n",
    "import numpy as np ## Numerical python for matrix operations\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler ## Preprocessing function\n",
    "#import pandas_profiling ## For easy profiling of pandas DataFrame\n",
    "#import missingno as msno ## Missing value co-occurance analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "from scipy import sparse\n",
    "from lightfm import LightFM\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def create_interaction_matrix(df,user_col, item_col, rating_col, norm= False, threshold = None):\n",
    "    '''\n",
    "    Function to create an interaction matrix dataframe from transactional type interactions\n",
    "    Required Input -\n",
    "        - df = Pandas DataFrame containing user-item interactions\n",
    "        - user_col = column name containing user's identifier\n",
    "        - item_col = column name containing item's identifier\n",
    "        - rating col = column name containing user feedback on interaction with a given item\n",
    "        - norm (optional) = True if a normalization of ratings is needed\n",
    "        - threshold (required if norm = True) = value above which the rating is favorable\n",
    "    Expected output - \n",
    "        - Pandas dataframe with user-item interactions ready to be fed in a recommendation algorithm\n",
    "    '''\n",
    "    interactions = df.groupby([user_col, item_col])[rating_col] \\\n",
    "            .sum().unstack().reset_index(). \\\n",
    "            fillna(0).set_index(user_col)\n",
    "    if norm:\n",
    "        interactions = interactions.applymap(lambda x: 1 if x > threshold else 0)\n",
    "    return interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_dict(interactions):\n",
    "    '''\n",
    "    Function to create a user dictionary based on their index and number in interaction dataset\n",
    "    Required Input - \n",
    "        interactions - dataset create by create_interaction_matrix\n",
    "    Expected Output -\n",
    "        user_dict - Dictionary type output containing interaction_index as key and user_id as value\n",
    "    '''\n",
    "    user_id = list(interactions.index)\n",
    "    user_dict = {}\n",
    "    counter = 0 \n",
    "    for i in user_id:\n",
    "        user_dict[i] = counter\n",
    "        counter += 1\n",
    "    return user_dict\n",
    "    \n",
    "def create_item_dict(df,id_col,name_col):\n",
    "    '''\n",
    "    Function to create an item dictionary based on their item_id and item name\n",
    "    Required Input - \n",
    "        - df = Pandas dataframe with Item information\n",
    "        - id_col = Column name containing unique identifier for an item\n",
    "        - name_col = Column name containing name of the item\n",
    "    Expected Output -\n",
    "        item_dict = Dictionary type output containing item_id as key and item_name as value\n",
    "    '''\n",
    "    item_dict ={}\n",
    "    for i in range(df.shape[0]):\n",
    "        item_dict[(df.loc[i,id_col])] = df.loc[i,name_col]\n",
    "    return item_dict\n",
    "\n",
    "def runMF(interactions, n_components=30, loss='warp', k=15, epoch=30,n_jobs = 4):\n",
    "    '''\n",
    "    Function to run matrix-factorization algorithm\n",
    "    Required Input -\n",
    "        - interactions = dataset create by create_interaction_matrix\n",
    "        - n_components = number of embeddings you want to create to define Item and user\n",
    "        - loss = loss function other options are logistic, brp\n",
    "        - epoch = number of epochs to run \n",
    "        - n_jobs = number of cores used for execution \n",
    "    Expected Output  -\n",
    "        Model - Trained model\n",
    "    '''\n",
    "    x = sparse.csr_matrix(interactions.values)\n",
    "    model = LightFM(no_components= n_components, loss=loss,k=k)\n",
    "    model.fit(x,epochs=epoch,num_threads = n_jobs)\n",
    "    return model\n",
    "\n",
    "def sample_recommendation_user(model, interactions, user_id, user_dict, \n",
    "                               item_dict,threshold = 0,nrec_items = 10, show = True):\n",
    "    '''\n",
    "    Function to produce user recommendations\n",
    "    Required Input - \n",
    "        - model = Trained matrix factorization model\n",
    "        - interactions = dataset used for training the model\n",
    "        - user_id = user ID for which we need to generate recommendation\n",
    "        - user_dict = Dictionary type input containing interaction_index as key and user_id as value\n",
    "        - item_dict = Dictionary type input containing item_id as key and item_name as value\n",
    "        - threshold = value above which the rating is favorable in new interaction matrix\n",
    "        - nrec_items = Number of output recommendation needed\n",
    "    Expected Output - \n",
    "        - Prints list of items the given user has already bought\n",
    "        - Prints list of N recommended items  which user hopefully will be interested in\n",
    "    '''\n",
    "    n_users, n_items = interactions.shape\n",
    "    user_x = user_dict[user_id]\n",
    "    scores = pd.Series(model.predict(user_x,np.arange(n_items)))\n",
    "    scores.index = interactions.columns\n",
    "    scores = list(pd.Series(scores.sort_values(ascending=False).index))\n",
    "    \n",
    "    known_items = list(pd.Series(interactions.loc[user_id,:] \\\n",
    "                                 [interactions.loc[user_id,:] > threshold].index) \\\n",
    "\t\t\t\t\t\t\t\t .sort_values(ascending=False))\n",
    "    \n",
    "    scores = [x for x in scores if x not in known_items]\n",
    "    return_score_list = scores[0:nrec_items]\n",
    "    known_items = list(pd.Series(known_items).apply(lambda x: item_dict[x]))\n",
    "    scores = list(pd.Series(return_score_list).apply(lambda x: item_dict[x]))\n",
    "    if show == True:\n",
    "        #print(\"Known Likes:\")\n",
    "        #counter = 1\n",
    "        #for i in known_items:\n",
    "        #    print(str(counter) + '- ' + i)\n",
    "        #    counter+=1\n",
    "\n",
    "        #print(\"\\n Recommended Items:\")\n",
    "        counter = 1\n",
    "        item_dic ={}\n",
    "        for i in scores:\n",
    "            #print(str(counter) + '- ' + str(i) )\n",
    "            #print(str(i))\n",
    "            item_dic.update({counter: str(i)})\n",
    "            counter+=1\n",
    "        print(item_dic)\n",
    "    return return_score_list\n",
    "    \n",
    "\n",
    "def sample_recommendation_item(model,interactions,item_id,user_dict,item_dict,number_of_user):\n",
    "    '''\n",
    "    Funnction to produce a list of top N interested users for a given item\n",
    "    Required Input -\n",
    "        - model = Trained matrix factorization model\n",
    "        - interactions = dataset used for training the model\n",
    "        - item_id = item ID for which we need to generate recommended users\n",
    "        - user_dict =  Dictionary type input containing interaction_index as key and user_id as value\n",
    "        - item_dict = Dictionary type input containing item_id as key and item_name as value\n",
    "        - number_of_user = Number of users needed as an output\n",
    "    Expected Output -\n",
    "        - user_list = List of recommended users \n",
    "    '''\n",
    "    n_users, n_items = interactions.shape\n",
    "    x = np.array(interactions.columns)\n",
    "    scores = pd.Series(model.predict(np.arange(n_users), np.repeat(x.searchsorted(item_id),n_users)))\n",
    "    user_list = list(interactions.index[scores.sort_values(ascending=False).head(number_of_user).index])\n",
    "    return user_list \n",
    "\n",
    "\n",
    "def create_item_emdedding_distance_matrix(model,interactions):\n",
    "    '''\n",
    "    Function to create item-item distance embedding matrix\n",
    "    Required Input -\n",
    "        - model = Trained matrix factorization model\n",
    "        - interactions = dataset used for training the model\n",
    "    Expected Output -\n",
    "        - item_emdedding_distance_matrix = Pandas dataframe containing cosine distance matrix b/w items\n",
    "    '''\n",
    "    df_item_norm_sparse = sparse.csr_matrix(model.item_embeddings)\n",
    "    similarities = cosine_similarity(df_item_norm_sparse)\n",
    "    item_emdedding_distance_matrix = pd.DataFrame(similarities)\n",
    "    item_emdedding_distance_matrix.columns = interactions.columns\n",
    "    item_emdedding_distance_matrix.index = interactions.columns\n",
    "    return item_emdedding_distance_matrix\n",
    "\n",
    "def item_item_recommendation(item_emdedding_distance_matrix, item_id, \n",
    "                             item_dict, n_items = 10, show = True):\n",
    "    '''\n",
    "    Function to create item-item recommendation\n",
    "    Required Input - \n",
    "        - item_emdedding_distance_matrix = Pandas dataframe containing cosine distance matrix b/w items\n",
    "        - item_id  = item ID for which we need to generate recommended items\n",
    "        - item_dict = Dictionary type input containing item_id as key and item_name as value\n",
    "        - n_items = Number of items needed as an output\n",
    "    Expected Output -\n",
    "        - recommended_items = List of recommended items\n",
    "    '''\n",
    "    recommended_items = list(pd.Series(item_emdedding_distance_matrix.loc[item_id,:]. \\\n",
    "                                  sort_values(ascending = False).head(n_items+1). \\\n",
    "                                  index[1:n_items+1]))\n",
    "    if show == True:\n",
    "        #print(\"Item of interest :{0}\".format(item_dict[item_id]))\n",
    "        #print(\"Item similar to the above item:\")\n",
    "        product_dic ={}\n",
    "        counter = 1\n",
    "        for i in recommended_items:\n",
    "            #print(str(counter) + '- ' +  item_dict[i])\n",
    "            product_dic.update({counter: item_dict[i]})\n",
    "            counter+=1\n",
    "        print(product_dic)\n",
    "    return recommended_items\n",
    "\n",
    "def random_item(num =10):\n",
    "    #l = [801001366,801001497,801001479,801001425,801001378,801001386,704000206,801001533,801001868,801001441,704000204,704000140,801001658,801001521]\n",
    "    #randomitem =  random.choice(l)\n",
    "    #return randomitem\n",
    "    s=['REVIVEREVIVE','CORDYCEPCORDYCEP','S.O.M.TIMECAPSULE','S.O.M.CMAX','REALELIXIRABALONECOLLAGEN','MAGIQUEYOUTHFULRADIANCE','S.O.M.CORDYTIBET&BHUTAN','LEKCAPPLEKCAPP','MAGIQUENOBLEWHITE','S.O.M.LINGZHISUN','S.O.M.I-KARE','PURECOLLAGENPURECOLLAGEN','S.O.M.TIMECAPSULE','MAGIQUEGRAVITAS','ULTIMATECOLLAGENULTIMATECOLLAGEN','BONBACKBONBACK','S.O.M.S-BALANCE','REVIVEREVIVEBLACKSHINE','MYCARDIMYCARDI','DERAEYDERAEY']\n",
    "    sampled_list = list(random.sample(s,num))\n",
    "\n",
    "    random_dic = {}\n",
    "    for i in range(len(sampled_list)):\n",
    "        random_dic.update({i+1: sampled_list[i]})\n",
    "    print(random_dic)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('D:/Dataset/DSRecommendation/V2/PurchaseHistory.csv',',' )\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings['BrandCollection'] = ratings['BrandCollection'].str.replace('|', '')\n",
    "ratings['BrandCollection'] = ratings['BrandCollection'].str.upper()\n",
    "ratings['BrandCollection'] = ratings['BrandCollection'].str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('D:/Dataset/DSRecommendation/V2/ProductMasters.csv',',')\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['BrandFamily'] = movies['BrandCollection']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['BrandCollection'] = movies['BrandCollection'].str.replace('|', '')\n",
    "movies['BrandCollection'] = movies['BrandCollection'].str.upper()\n",
    "movies['BrandCollection'] = movies['BrandCollection'].str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1) Create interaction matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = create_interaction_matrix(df = ratings,\n",
    "                                         user_col = 'Customer_offline',\n",
    "                                         item_col = 'BrandCollection',\n",
    "                                         rating_col = 'Quantity',\n",
    "                                         threshold = '3')\n",
    "interactions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2) Create User Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dict = create_user_dict(interactions=interactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3) Create Item dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_dict = create_item_dict(df = movies,\n",
    "                               id_col = 'BrandCollection',\n",
    "                               name_col = 'BrandFamily')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##interactions = np.array(interactions, dtype=float)\n",
    "#interac = interactions\n",
    "##features.astype(np.float)\n",
    "x = sparse.csr_matrix(interactions.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightFM(no_components= 10, loss='warp',k=10)\n",
    " # model.fit(x,epochs=epoch,num_threads = n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_model = model.fit(x,epochs=5,num_threads =4,verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm.evaluation import auc_score\n",
    "\n",
    "NUM_THREADS = 2\n",
    "NUM_COMPONENTS = 30\n",
    "NUM_EPOCHS = 3\n",
    "ITEM_ALPHA = 1e-6\n",
    "\n",
    "# Compute and print the AUC score\n",
    "train_auc = auc_score(mf_model, x, num_threads=NUM_THREADS).mean()\n",
    "print('Collaborative filtering train AUC: %s' % train_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'd:/finalized_model_V2.sav'\n",
    "pickle.dump(mf_model, open(filename, 'wb'))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Building Matrix Factorization model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mf_model = runMF(interactions = interactions,\n",
    " #                n_components = 30,\n",
    "#                 loss = 'warp',\n",
    "#                 k = '15',\n",
    "#                 epoch = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) User Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_list = sample_recommendation_user(model = loaded_model, \n",
    "                                      interactions = interactions, \n",
    "                                      user_id = 'CE0001178', \n",
    "                                      user_dict = user_dict,\n",
    "                                      item_dict = product_dict, \n",
    "                                      threshold = 4,\n",
    "                                      nrec_items = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Item-User Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_recommendation_item(model = loaded_model,\n",
    "                           interactions = interactions,\n",
    "                           item_id = 'ACTIVISACTIVIS',\n",
    "                           user_dict = user_dict,\n",
    "                           item_dict = product_dict,\n",
    "                           number_of_user = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Item - Item Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_dist = create_item_emdedding_distance_matrix(model = loaded_model,\n",
    "                                                       interactions = interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'd:/ItemMatrix_V2.sav'\n",
    "pickle.dump(item_item_dist, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemMatrix = pickle.load(open('d:/ItemMatrix_V2.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'd:/ProductDict_V2.sav'\n",
    "pickle.dump(product_dict, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'd:/UserDict_V2.sav'\n",
    "pickle.dump(user_dict, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'd:/InterActions_V2.sav'\n",
    "pickle.dump(interactions, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_list = item_item_recommendation(item_emdedding_distance_matrix = itemMatrix,\n",
    "                                    item_id = 'DDNEEDDNEE',\n",
    "                                    item_dict = product_dict,\n",
    "                                    n_items = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "product_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_items = list(pd.Series(itemMatrix.loc[801001026,:]. \\\n",
    "                                  sort_values(ascending = False).head(10+1). \\\n",
    "                                  index[1:10+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ['Revive|Revive', 'Cordycep|Cordycep','S.O.M.|Time Capsule','S.O.M.|C Max','Real Elixir|Abalone Collagen','Magique|Youthful Radiance','S.O.M.|Cordy Tibet & Bhutan',\n",
    "'Lekcapp|Lekcapp','Magique|Noble White','S.O.M.|Lingzhi Sun','S.O.M.|I-Kare','Pure Collagen|Pure Collagen','S.O.M.|TIME CAPSULE','Magique|Gravitas','Ultimate Collagen|Ultimate Collagen',\n",
    "'BONBACK|BONBACK','S.O.M.|S-Balance','Revive|Revive Black Shine','My Cardi|My Cardi','DERAEY|DERAEY']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s = ['Revive|Revive', 'Cordycep|Cordycep','S.O.M.|Time Capsule','S.O.M.|C Max','Real Elixir|Abalone Collagen','Magique|Youthful Radiance','S.O.M.|Cordy Tibet & Bhutan',\n",
    "'Lekcapp|Lekcapp','Magique|Noble White','S.O.M.|Lingzhi Sun','S.O.M.|I-Kare','Pure Collagen|Pure Collagen','S.O.M.|TIME CAPSULE','Magique|Gravitas','Ultimate Collagen|Ultimate Collagen',\n",
    "'BONBACK|BONBACK','S.O.M.|S-Balance','Revive|Revive Black Shine','My Cardi|My Cardi','DERAEY|DERAEY']\n",
    "sampled_list = list(random.sample(s,5))\n",
    "\n",
    "dic = {}\n",
    "for i in range(len(s)):\n",
    "    dic.update({i: sampled_list[i]})\n",
    "\n",
    "print(dic)\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
